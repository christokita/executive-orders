rm(list=ls())
library(idaTopicModels)
library(idaMakeDtm)
library(dplyr)
library(igraph)
##################################################################################################
# Initial data pruning
##################################################################################################
# Load Data
load("data/eoMatchesUncurated.RData")
# Remove matches column and duplicates
eos <-
eoMatchesUncurated %>%
select(-matches) %>% #drop matches column
unique() %>% #remove duplicates
mutate(title_text = paste(title, eoText, sep = " ")) #create title and text column
match_words <- c("scien.*", "technolog.*", "research.*")
# match_words <- c("office of science and technology policy", "[^A-Za-z]+OSTP[^A-Za-z]+",
#                  "national aeronautics and space administration", "[^A-Za-z]+NASA[^A-Za-z]+",
#                  "national science foundation", "[^A-Za-z]+NSF[^A-Za-z]+",
#                  "national institute of health", "[^A-Za-z]+NIH[^A-Za-z]+")
match_words <- paste0(match_words, collapse = "|")
eos <-
eos %>%
filter(grepl(pattern = match_words, x = title_text, ignore.case = TRUE)) %>%
unique()
rm(eoMatchesUncurated)
mean(nchar(eos$eoText))
median(nchar(eos$eoText))
hist(nchar(eos$eoText))
eo_text <- eos$eoText
names(eo_text) <- eos$num
dtm <- Vec2Dtm(vec = eo_text,
min.n.gram = 1,
max.n.gram = 2,
remove.stopwords = TRUE)
rm(list=ls())
library(idaTopicModels)
library(idaMakeDtm)
library(dplyr)
library(igraph)
##################################################################################################
# Initial data pruning
##################################################################################################
# Load Data
load("data/eoMatchesUncurated.RData")
# Remove matches column and duplicates
eos <-
eoMatchesUncurated %>%
select(-matches) %>% #drop matches column
unique() %>% #remove duplicates
mutate(title_text = paste(title, eoText, sep = " ")) #create title and text column
match_words <- c("scien.*", "technolog.*", "research.*")
# match_words <- c("office of science and technology policy", "[^A-Za-z]+OSTP[^A-Za-z]+",
#                  "national aeronautics and space administration", "[^A-Za-z]+NASA[^A-Za-z]+",
#                  "national science foundation", "[^A-Za-z]+NSF[^A-Za-z]+",
#                  "national institute of health", "[^A-Za-z]+NIH[^A-Za-z]+")
match_words <- paste0(match_words, collapse = "|")
eos <-
eos %>%
filter(grepl(pattern = match_words, x = title_text, ignore.case = TRUE)) %>%
unique()
rm(eoMatchesUncurated)
##################################################################################################
# Checking characterisitings of dataset
##################################################################################################
#Average character length of EOs
mean(nchar(eos$eoText))
median(nchar(eos$eoText))
hist(nchar(eos$eoText))
##################################################################################################
# Modeling
##################################################################################################
# EO Text only for DTm production
eo_text <- eos$eoText
names(eo_text) <- eos$num
# Create DTM
dtm <- Vec2Dtm(vec = eo_text,
min.n.gram = 1,
max.n.gram = 2,
remove.stopwords = TRUE)
dtm <- DepluralizeDtm(dtm = dtm)
tf <- TermDocFreq(dtm = dtm)
keep_terms <- tf$term[ tf$doc.freq < nrow(dtm)/2 & tf$doc.freq > 4]
dtm <- dtm[, keep_terms]
summary(rowSums(dtm)) #check to make sure all documents have words
lex <- Dtm2Docs(dtm = dtm, parallel = TRUE, cpus = 8)
vocab <- colnames(dtm)
lex <- lexicalize(doclines = lex, sep = " ",
lower = TRUE,
vocab = vocab)
k_list <- seq(10, 130, by = 10)
names(k_list) <- paste("k", k_list, sep = "_")
k_list
sfInit(parallel = TRUE, cpus = 8)
sfExport(list = c("vocab", "lex"))
sfLibrary(idaTopicModels)
models <- sfLapply(k_list, fun = function(k){
lda.collapsed.gibbs.sampler(documents = lex,
K = k,
vocab = vocab,
num.iterations = 5000,
alpha = 0.1,
eta = 0.05,
compute.log.likelihood = TRUE)
})
#num.iterations: for play 500, for research 2,000-20,000
sfStop()
########## Explore Models ###########
names(models)
models <- lapply(models, function(M){
FormatRawLdaOutput(lda.result = M, docnames = rownames(dtm), smooth = TRUE)
})
models <- lapply(models, function(M){
M$coherence <- apply(M$phi, 1, function(x) ProbCoherence(topic = x, dtm = dtm, M = 6))
M$prevalence <- colSums(M$theta) / sum(colSums(M$theta)) * 100
M$r2 <- TopicModelR2(dtm = dtm, phi = M$phi, theta= M$theta, parallel = FALSE) #faster to use parallel for greater than 5-10 thousand documents
M$ll <- CalcLikelihood(dtm = dtm, phi = M$phi, theta = M$theta, parallel = FALSE)
return(M)
})
metric_mat <- lapply(models, function(M){
data.frame(k = ncol(M$theta),
ll1 = M$likelihood[1, ncol(M$likelihood)],
ll2 = M$likelihood[2, ncol(M$likelihood)],
ll3 = M$ll,
coherence = mean(M$coherence),
r2 = M$r2$r2,
stringsAsFactors = FALSE)
})
metric_mat <- do.call(rbind, metric_mat)
metric_mat <- metric_mat[ order(metric_mat$k), ]
plot(metric_mat$k, metric_mat$ll1, type = "o") # most useful ll for now
plot(metric_mat$k, metric_mat$coherence, type = "o")#always gets right number of topics in simulated data
plot(metric_mat$k, metric_mat$ll1, type = "o") # most useful ll for now
plot(metric_mat$k, metric_mat$ll2, type = "o")
plot(metric_mat$k, metric_mat$ll3, type = "o")
plot(metric_mat$k, metric_mat$coherence, type = "o")#always gets right number of topics in simulated data
plot(metric_mat$k, metric_mat$r2, type = "o")
plot(metric_mat$k, metric_mat$coherence, type = "o")#always gets right number of topics in simulated data
save(models, metric_mat, file = "Topic Modeling/data/ST_models.Rdata")
final_model <- models$k_60
final_model$phi_prime <- GetPhiPrime(phi = final_model$phi, theta = final_model$theta)
final_model$top_terms_raw <- GetTopTerms(phi = final_model$phi, M = 10)
final_model$top_terms_prime <- GetTopTerms(phi = final_model$phi_prime, M = 10)
# Create output
final_model$summary <- data.frame(Topic = rownames(final_model$phi),
Coherence = final_model$coherence,
Prevalence = final_model$prevalence,
TT_raw = apply(final_model$top_terms_raw, 2, function(x) paste(x, collapse = ", ")),
TT_prime = apply(final_model$top_terms_prime, 2, function(x) paste(x, collapse = ", ")),
stringsAsFactors = FALSE)
View(final_model$summary)
summary <- final_model$summary
write.table(summary,
file = "X:/___STPIData/ExecutiveOrders/Topic Modeling/output/ST_Topic_60_Summary.csv",
sep = ",",
col.names = TRUE,
row.names = FALSE)
# Document Topic dataframe
final_model$assignments <- t(apply(final_model$theta, 1, function(x) {
x[ x < 0.05 ] <- 0
x / sum(x)
}))
doc.topic <- final_model$assignments
write.table(doc.topic,
file = "X:/___STPIData/ExecutiveOrders/Topic Modeling/output/ST_Topic_60_DocTopMatrix.csv",
sep = ",",
col.names = NA,
row.names = TRUE)
plot(metric_mat$k, metric_mat$ll1, type = "o") # most useful ll for now
rm(list=ls())
library(idaTopicModels)
load("Topic Modeling/data/ST_models.Rdata")
final_model <- models$k_60
# Get stuff out of final model
final_model$phi_prime <- GetPhiPrime(phi = final_model$phi, theta = final_model$theta)
final_model$top_terms_raw <- GetTopTerms(phi = final_model$phi, M = 10)
final_model$top_terms_prime <- GetTopTerms(phi = final_model$phi_prime, M = 10)
final_model <- models$k_60
final_model$phi_prime <- GetPhiPrime(phi = final_model$phi, theta = final_model$theta)
library(idaMakeDtm)
library(idaMakeDtm)
library(idaTopicModels)
install.packages("devtools") # if you haven't installed devtools before
install("//div-stpi/public/___STPI_Tools/IDA_Text_Mining_Libraries/idaTopicModels/")
library(devtools)
install("//div-stpi/public/___STPI_Tools/IDA_Text_Mining_Libraries/idaTopicModels/")
install("//div-stpi/public/___STPI_Tools/IDA_Text_Mining_Libraries/idaMakeDtm/")
library(idaTopicModels)
library(idaMakeDtm)
final_model <- models$k_60
final_model$phi_prime <- GetPhiPrime(phi = final_model$phi, theta = final_model$theta)
final_model$top_terms_raw <- GetTopTerms(phi = final_model$phi, M = 10)
final_model$top_terms_prime <- GetTopTerms(phi = final_model$phi_prime, M = 10)
# Create output
final_model$summary <- data.frame(Topic = rownames(final_model$phi),
Coherence = final_model$coherence,
Prevalence = final_model$prevalence,
TT_raw = apply(final_model$top_terms_raw, 2, function(x) paste(x, collapse = ", ")),
TT_prime = apply(final_model$top_terms_prime, 2, function(x) paste(x, collapse = ", ")),
stringsAsFactors = FALSE)
View(final_model$summary)
summary <- final_model$summary
final_model$assignments <- t(apply(final_model$theta, 1, function(x) {
x[ x < 0.05 ] <- 0
x / sum(x)
}))
doc.topic <- final_model$assignments
dtm <- doc.topic
save(final_model, summary, dtm, file  = "Topic Modeling/data/k60_ST_model")
rm(list=ls())
library(idaTopicModels)
load("Topic Modeling/data/k60_ST_model")
labels <- apply(final_model$theta, 1, function(x) as.numeric(x == max(x)) )
sfInit(parallel=T, cpus=8)
labels <- apply(final_model$theta, 1, function(x) as.numeric(x == max(x)) )
sfInit(parallel=T, cpus=8)
sfExport("dtm")
sfLibrary(idaTopicModels)
final_model$labels <- sfApply(labels, 1, function(x){
result <- GetProbableTerms(docnames = names(x)[ x == 1 ], dtm = dtm[ , grepl("_", colnames(dtm)) ])
return(names(result)[ order(result, decreasing=T) ][ 1 ])
})
sfStop()
final_model$summary <- data.frame(topic=rownames(final_model$phi),
label=final_model$labels,
tt=apply(final_model$top_terms, 2, function(x) paste(x, collapse=", ")),
tt_prime=apply(final_model$top_terms_prime, 2, function(x) paste(x, collapse=", ")),
coherence=round(final_model$coherence, 2),
prevalence=final_model$prevalence,
stringsAsFactors=FALSE)
final_model$summary <- data.frame(topic = rownames(final_model$phi),
label = final_model$labels,
tt_raw = apply(final_model$top_terms, 2, function(x) paste(x, collapse=", ")),
tt_prime = apply(final_model$top_terms_prime, 2, function(x) paste(x, collapse=", ")),
coherence = round(final_model$coherence, 2),
prevalence = final_model$prevalence,
stringsAsFactors = FALSE)
names(final_model)
##################################################################
final_model$summary <- data.frame(topic = rownames(final_model$phi),
label = final_model$labels,
tt_raw = apply(final_model$top_terms_raw, 2, function(x) paste(x, collapse=", ")),
tt_prime = apply(final_model$top_terms_prime, 2, function(x) paste(x, collapse=", ")),
coherence = round(final_model$coherence, 2),
prevalence = final_model$prevalence,
stringsAsFactors = FALSE)
rm(list=ls())
library(idaTopicModels)
load("Topic Modeling/data/k60_ST_model")
labels <- apply(final_model$theta, 1, function(x) as.numeric(x == max(x)) )
labels
sfInit(parallel=T, cpus=8)
labels <- apply(final_model$theta, 1, function(x) as.numeric(x == max(x)) )
sfInit(parallel=T, cpus=8)
sfExport("dtm")
sfLibrary(idaTopicModels)
final_model$labels <- sfApply(labels, 1, function(x){
result <- GetProbableTerms(docnames = names(x)[ x == 1 ], dtm = dtm[ , grepl("_", colnames(dtm)) ])
return(names(result)[ order(result, decreasing=T) ][ 1 ])
})
sfStop()
final_model$summary <- data.frame(topic = rownames(final_model$phi),
label = final_model$labels,
tt_raw = apply(final_model$top_terms_raw, 2, function(x) paste(x, collapse=", ")),
tt_prime = apply(final_model$top_terms_prime, 2, function(x) paste(x, collapse=", ")),
coherence = round(final_model$coherence, 2),
prevalence = final_model$prevalence,
stringsAsFactors = FALSE)
final_model$theta
labels <- apply(final_model$theta, 1, function(x) as.numeric(x == max(x)) )
View(labels)
sfInit(parallel=T, cpus=8)
sfStop()
sfInit(parallel=T, cpus=8)
sfExport("dtm")
sfLibrary(idaTopicModels)
final_model$labels <- sfApply(labels, 1, function(x){
result <- GetProbableTerms(docnames = names(x)[ x == 1 ], dtm = dtm[ , grepl("_", colnames(dtm)) ])
return(names(result)[ order(result, decreasing=T) ][ 1 ])
})
sfStop()
dtm
final_model$labels <- sfApply(labels, 1, function(x){
result <- GetProbableTerms(docnames = names(x)[ x == 1 ], dtm = dtm[ , grepl("_", colnames(dtm)) ])
return(names(result)[ order(result, decreasing=T) ][ 1 ])
})
dtm[ , grepl("_", colnames(dtm)) ]
rm(list=ls())
library(idaTopicModels)
load("Topic Modeling/data/k60_ST_model")
##################################################################
# Get Topic Labels
##################################################################
labels <- apply(final_model$theta, 1, function(x) as.numeric(x == max(x)) )
sfInit(parallel=T, cpus=8)
sfExport("dtm")
sfLibrary(idaTopicModels)
final_model$labels <- sfApply(labels, 1, function(x){
result <- GetProbableTerms(docnames = names(x)[ x == 1 ], dtm = dtm[ , grepl("_", colnames(dtm)) ])
return(names(result)[ order(result, decreasing=T) ][ 1 ])
})
sfStop()
str(final_model)
labels[1]
labels[1,]
labels
x <- labels[1,]
result <- GetProbableTerms(docnames = names(x)[ x == 1 ], dtm = dtm[ , grepl("_", colnames(dtm)) ])
x
final_model$theta
final_model$theta[1]
test <- final_model$theta
test
View(test)
x <- test[1,]
as.numeric(x == max(x))
labels <- apply(final_model$theta, 1, function(x) as.numeric(x == max(x)) )
x <- labels[1,]
x
View(labels)
View(labels)
colSums(labels)
