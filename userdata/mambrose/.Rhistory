#   text <- gsub("<.*?>", "", content) #remove html tags
#
#   return(text)
}
nums <- 1:10
presDocs <- lapply(nums, scrapeGPO, year = "2014")
rm(list = ls())
library(RCurl)
library(stringr)
scrapeGPO <- function(num, year){
num <- str_pad(string = num, width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", year, num, "/html/DCPD-", year, num , ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
return(text)
}
nums <- 1:10
presDocs <- lapply(nums, scrapeGPO, year = "2014")
library(plyr)
presDocs2 <-ldply(presDocs)
View(presDocs2)
presDocs2$V1[1]
presDocs2$V1[2]
rm(list = ls())
library(RCurl)
library(stringr)
scrapeGPO <- function(num, year){
num <- str_pad(string = num, width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", year, num, "/html/DCPD-", year, num , ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
return(text)
}
nums <- 1:960
presDocs <- lapply(nums, scrapeGPO, year = "2014")
rm(list = ls())
library(RCurl)
library(stringr)
scrapeGPO <- function(num, year){
Sys.sleep(0.1)
num <- str_pad(string = num, width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", year, num, "/html/DCPD-", year, num , ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
try(df <- data.frame(doc.text = text, link = url))
return(df)
}
nums <- 1:10
presDocs <- lapply(nums, scrapeGPO, year = "2014")
library(plyr)
presDocs2 <-ldply(presDocs)
View(presDocs2)
rm(list = ls())
library(RCurl)
library(stringr)
scrapeGPO <- function(num, year){
Sys.sleep(0.1)
num <- str_pad(string = num, width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", year, num, "/html/DCPD-", year, num , ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
try(df <- data.frame(doc.text = text, link = url))
return(df)
}
nums <- 1:960
presDocs <- lapply(nums, scrapeGPO, year = "2014")
library(plyr)
presDocs2 <-ldply(presDocs)
pm <- presDocs2 %>%
filter(str_detect_all(string = doc.text, pattern = "Memorandum"))
library(stringr)
pm <- presDocs2 %>%
filter(str_detect_all(string = doc.text, pattern = "Memorandum"))
?str_detect
pm <- presDocs2 %>%
filter(str_detect(string = doc.text, pattern = "Memorandum"))
pm.trim <- presDocs2 %>%
filter(str_detect(string = doc.text, pattern = "Memorandum")) %>%
filter(str_detect(string = doc.text, pattern = ignore.case("National Strategy"))
)
View(pm)
pm$doc.text[1]
rm(list = ls())
library(RCurl)
library(stringr)
scrapeGPO <- function(num, year){
Sys.sleep(0.1)
num <- str_pad(string = num, width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", year, num, "/html/DCPD-", year, num , ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
try(df <- data.frame(doc.text = text, link = url, stringsAsFactors = F))
return(df)
}
gpoDocNums <- read.csv(file = "data/gpoDocNumRanges.csv", stringsAsFactors = F)
?apply
rm(list = ls())
library(RCurl)
library(stringr)
scrapeGPO <- function(num, year){
Sys.sleep(0.1)
num <- str_pad(string = num, width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", year, num, "/html/DCPD-", year, num , ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
try(df <- data.frame(doc.text = text, link = url, stringsAsFactors = F))
return(df)
}
gpoDocNums <- read.csv(file = "data/gpoDocNumRanges.csv", stringsAsFactors = F)
presDocs <- apply(X = gpoDocNums, MARGIN = 1, FUN = scrapeGPO, num = x[2], year = x[1])
rm(list = ls())
library(RCurl)
library(stringr)
scrapeGPO <- function(num, year){
Sys.sleep(0.1)
num <- str_pad(string = num, width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", year, num, "/html/DCPD-", year, num , ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
try(df <- data.frame(doc.text = text, link = url, stringsAsFactors = F))
return(df)
}
gpoDocNums <- read.csv(file = "data/gpoDocNumRanges.csv", stringsAsFactors = F)
#presDocs <- lapply(nums, scrapeGPO, year = "2014")
presDocs <- apply(X = gpoDocNums, MARGIN = 1, FUN = scrapeGPO(x[2], x[1]))
rm(list = ls())
library(RCurl)
library(stringr)
scrapeGPO <- function(num, year){
Sys.sleep(0.1)
num <- str_pad(string = num, width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", year, num, "/html/DCPD-", year, num , ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
try(df <- data.frame(doc.text = text, link = url, stringsAsFactors = F))
return(df)
}
gpoDocNums <- read.csv(file = "data/gpoDocNumRanges.csv", stringsAsFactors = F)
presDocs <- apply(X = gpoDocNums, MARGIN = 1, FUN = function(x[1], x[2]){
Sys.sleep(0.1)
num <- str_pad(string = x[2], width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", x[1], num, "/html/DCPD-", x[1], num, ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
try(df <- data.frame(doc.text = text, link = url, stringsAsFactors = F))
return(df)
}
rm(list = ls())
library(RCurl)
library(stringr)
scrapeGPO <- function(num, year){
Sys.sleep(0.1)
num <- str_pad(string = num, width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", year, num, "/html/DCPD-", year, num , ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
try(df <- data.frame(doc.text = text, link = url, stringsAsFactors = F))
return(df)
}
gpoDocNums <- read.csv(file = "data/gpoDocNumRanges.csv", stringsAsFactors = F)
#presDocs <- lapply(nums, scrapeGPO, year = "2014")
presDocs <- apply(X = gpoDocNums, MARGIN = 1, FUN = function(x[1], x[2]){
Sys.sleep(0.1)
num <- str_pad(string = x[2], width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", x[1], num, "/html/DCPD-", x[1], num, ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
try(df <- data.frame(doc.text = text, link = url, stringsAsFactors = F))
return(df)
})
rm(list = ls())
library(RCurl)
library(stringr)
scrapeGPO <- function(num, year){
Sys.sleep(0.1)
num <- str_pad(string = num, width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", year, num, "/html/DCPD-", year, num , ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
try(df <- data.frame(doc.text = text, link = url, stringsAsFactors = F))
return(df)
}
gpoDocNums <- read.csv(file = "data/gpoDocNumRanges.csv", stringsAsFactors = F)
#presDocs <- lapply(nums, scrapeGPO, year = "2014")
presDocs <- apply(X = gpoDocNums, MARGIN = 1, FUN = function(x){
Sys.sleep(0.1)
num <- str_pad(string = x[2], width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", x[1], num, "/html/DCPD-", x[1], num, ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
try(df <- data.frame(doc.text = text, link = url, stringsAsFactors = F))
return(df)
})
presDocs2 <-ldply(presDocs)
View(presDocs2)
?apply
rm(list = ls())
library(RCurl)
library(stringr)
scrapeGPO <- function(num, year){
Sys.sleep(0.01)
num <- str_pad(string = num, width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", year, num, "/html/DCPD-", year, num , ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
try(df <- data.frame(doc.text = text, link = url, stringsAsFactors = F))
return(df)
}
gpoDocNums <- read.csv(file = "data/gpoDocNumRanges.csv", stringsAsFactors = F)
presDocs2014 <- lapply(nums, scrapeGPO, year = "2014")
1:gpoDocNums[gpoDocNums$year == "2014", ]$end.num
rm(list = ls())
library(RCurl)
library(stringr)
scrapeGPO <- function(num, year){
Sys.sleep(0.01)
num <- str_pad(string = num, width = 5, pad = "0")
url <- paste0("http://www.gpo.gov/fdsys/pkg/DCPD-", year, num, "/html/DCPD-", year, num , ".htm")
print(url)
content <- getURL(url) #get webpage url
text <- gsub("<.*?>", "", content) #remove html tags
try(df <- data.frame(doc.text = text, link = url, stringsAsFactors = F))
return(df)
}
gpoDocNums <- read.csv(file = "data/gpoDocNumRanges.csv", stringsAsFactors = F)
presDocs2014 <- lapply(1:gpoDocNums[gpoDocNums$year == "2014", ]$end.num, scrapeGPO, year = "2014")
presDocs2013 <- lapply(1:gpoDocNums[gpoDocNums$year == "2013", ]$end.num, scrapeGPO, year = "2013")
presDocs2012 <- lapply(1:gpoDocNums[gpoDocNums$year == "2012", ]$end.num, scrapeGPO, year = "2012")
presDocs <- c(presDocs2014, presDocs2013, presDocs2012)
presDocs <- ldply(presDocs)
View(presDocs)
presDocs2015 <- lapply(1:gpoDocNums[gpoDocNums$year == "2015", ]$end.num, scrapeGPO, year = "2015")
gpoDocNums <- read.csv(file = "data/gpoDocNumRanges.csv", stringsAsFactors = F)
presDocs2015 <- lapply(1:gpoDocNums[gpoDocNums$year == "2015", ]$end.num, scrapeGPO, year = "2015")
gpoDocNums <- read.csv(file = "data/gpoDocNumRanges.csv", stringsAsFactors = F)
presDocs2015 <- lapply(1:gpoDocNums[gpoDocNums$year == "2015", ]$end.num, scrapeGPO, year = "2015")
presDocs <- c(presDocs2015, presDocs2014, presDocs2013, presDocs2012)
presDocs <- ldply(presDocs)
save(presDocs, file = "data/gpoPresidentialDocuments.RData")
pm <- presDocs %>%
filter(str_detect(string = doc.text, pattern = "Memorandum"))
pm.trim <- presDocs %>%
filter(str_detect(string = doc.text, pattern = "Memorandum")) %>%
filter(str_detect(string = doc.text, pattern = ignore.case("National Strategy")))
View(pm.trim)
pm.trim$doc.text
pm.trim$link
presDocs2011 <- lapply(1:gpoDocNums[gpoDocNums$year == "2011", ]$end.num, scrapeGPO, year = "2011")
presDocs2010 <- lapply(1:gpoDocNums[gpoDocNums$year == "2010", ]$end.num, scrapeGPO, year = "2010")
presDocs2009 <- lapply(1:gpoDocNums[gpoDocNums$year == "2009", ]$end.num, scrapeGPO, year = "2009")
presDocs <- c(presDocs2015, presDocs2014, presDocs2013, presDocs2012, presDocs2011, presDocs2010, presDocs2009)
presDocs <- ldply(presDocs)
save(presDocs, file = "data/gpoPresidentialDocuments.RData")
pm <- presDocs %>%
filter(str_detect(string = doc.text, pattern = "Memorandum"))
pm.ns <- presDocs %>%
filter(str_detect(string = doc.text, pattern = "Memorandum")) %>%
filter(str_detect(string = doc.text, pattern = ignore.case("National Strategy")))
ns <- presDocs %>%
filter(str_detect(string = doc.text, pattern = ignore.case("National Strategy")))
ns$link
cat(ns$link, sep = "\n cygstart ")
pm.ns <- presDocs %>%
filter(str_detect(string = doc.text, pattern = "Memorandum")) %>%
filter(str_detect(string = doc.text, pattern = ignore.case("National Strategy|Federal Strategy")))
ns <- presDocs %>%
filter(str_detect(string = doc.text, pattern = ignore.case("National Strategy|Federal Strategy")))
View(pm.ns)
cat(pm.ns$link, sep = "\ncygstart ")
s <- presDocs %>%
filter(str_detect(string = doc.text, pattern = "Strategy"))
s <- presDocs %>%
filter(str_detect(string = doc.text, pattern = "Memorandum")) %>%
filter(str_detect(string = doc.text, pattern = "Strategy"))
cat(s$link, sep = "\ncygstart ")
for(i in nrow(gpoDocNums)){
print(gpoDocNums$year[i])
}
for(i in 1:nrow(gpoDocNums)){
print(gpoDocNums$year[i])
}
?seq
years <- seq(from = 1993, to = 2008, by = 1)
for(i in length(years)){
url <- paste0("http://www.gpo.gov/fdsys/browse/collection.action?collectionCode=CPD&browsePath=",
years[i],
"&isCollapsed=false&leafLevelBrowse=false&ycord=100")
print(url)
}
rm(list = ls())
years <- seq(from = 1993, to = 2008, by = 1)
for(i in 1:length(years)){
url <- paste0("http://www.gpo.gov/fdsys/browse/collection.action?collectionCode=CPD&browsePath=",
years[i],
"&isCollapsed=false&leafLevelBrowse=false&ycord=100")
print(url)
}
content <- getURL(url) #get webpage url
library(RCurl)
library(stringr)
library(plyr)
content <- getURL(url) #get webpage url
content <- unlist(strsplit(content, "\n"))
months <- seq(from = 1, to = 12, by = 1)
?str_pad
months <- str_pad(string = months, width = 2, pad = "0")
i <- 2
months <- seq(from = 1, to = 12, by = 1)
months <- str_pad(string = months, width = 2, pad = "0")
j <- 3
url <- paste0("http://www.gpo.gov/fdsys/browse/collection.action?collectionCode=CPD&browsePath=",
years[i],
"%2F", months[j],
"&isCollapsed=false&leafLevelBrowse=false")
url
content <- getURL(url) #get webpage url
content <- unlist(strsplit(content, "\n"))
links <- str_match_all(string = "http://www.gpo.gov:80/fdsys/pkg/WCPD")
links <- str_match_all(string = content, pattern = "http://www.gpo.gov:80/fdsys/pkg/WCPD")
content <- unlist(strsplit(content, "\r\n"))
content <- getURL(url) #get webpage url
content <- unlist(strsplit(content, "\r\n"))
head(content)
head(content, n=100)
links <- content[str_match_all(string = content, pattern = "http://www.gpo.gov:80/fdsys/pkg/WCPD")]
links <- content[str_detect(string = content, pattern = "http://www.gpo.gov:80/fdsys/pkg/WCPD")]
links
links2 <- unlist(str_match_all(string = links, pattern = "http://www.gpo.gov:80/fdsys/pkg/WCPD*?htm")
)
?str_match_all
?str_detect
links <- content[str_detect(string = content, pattern = fixed("http://www.gpo.gov:80/fdsys/pkg/WCPD"))]
links2 <- unlist(str_match_all(string = links, pattern = "http://www\\.gpo\\.gov:80/fdsys/pkg/WCPD*?htm"))
links2 <- unlist(str_match_all(string = links, pattern = "http://www\\.gpo\\.gov:80/fdsys/pkg/WCPD*?\\.htm"))
?str_match_all
links2 <- str_match_all(string = links, pattern = "http://www\\.gpo\\.gov:80/fdsys/pkg/WCPD*?\\.htm")
links2 <- str_replace_ll(string = links, pattern = ".*(http://www\\.gpo\\.gov:80/fdsys/pkg/WCPD*?\\.htm).*", replacement = "\\1")
links2 <- str_replace_all(string = links, pattern = ".*(http://www\\.gpo\\.gov:80/fdsys/pkg/WCPD*?\\.htm).*", replacement = "\\1")
links2 <- str_replace_all(string = links, pattern = perl(".*(http://www\\.gpo\\.gov:80/fdsys/pkg/WCPD*?\\.htm).*"), replacement = "\\1")
links2 <- str_replace_all(string = links, pattern = perl(".*(http://www\\.gpo\\.gov:80/fdsys/pkg/WCPD*?\\.htm).*"), replacement = perl("\\1"))
?str_replace_all
?gsub
links2 <- gsub(pattern = ".*(http://www\\.gpo\\.gov:80/fdsys/pkg/WCPD*?\\.htm).*", replacement = "\\1", perl = T)
links2 <- gsub(x = links, pattern = ".*(http://www\\.gpo\\.gov:80/fdsys/pkg/WCPD*?\\.htm).*", replacement = "\\1", perl = T)
head(links)
links2 <- gsub(x = links, pattern = ".*(http://www\\.gpo\\.gov:80/fdsys/pkg/WCPD*?\\.htm).*", replacement = "\\1", perl = T)
head(links2)
links2 <- gsub(x = links, pattern = ".*(http://www\.gpo\.gov:80/fdsys/pkg/WCPD*?\.htm).*", replacement = "\\1", perl = T)
links[1]
links2 <- gsub(x = links, pattern = ".*(http://www\\.gpo\\.gov:80/fdsys/pkg/WCPD*\\.htm).*", replacement = "\\1", perl = T)
?gsub
links2 <- gsub(pattern = ".*(http://www\\.gpo\\.gov:80/fdsys/pkg/WCPD*\\.htm).*", replacement = "\\1", x = links, ignore.cast = T, perl = T)
links2 <- gsub(pattern = ".*(http://www\\.gpo\\.gov:80/fdsys/pkg/WCPD*\\.htm).*", replacement = "\\1", x = links, ignore.case = T, perl = T)
rm(list = ls())
library(RCurl)
library(stringr)
library(plyr)
library(dplyr)
year <- "2014"
month <- "02"
scrapeGPO <- function(year){
months <- seq(from = 1, to = 12, by = 1)
months <- str_pad(string = months, width = 2, pad = "0")
result <- lapply(months, FUN = function(month){
Sys.sleep(0.01)
url <- paste0("http://www.gpo.gov/fdsys/browse/collection.action?collectionCode=CPD&browsePath=",
year,
"%2F", month,
"&isCollapsed=false&leafLevelBrowse=false")
print(paste0(year, ", ", month))
content <- getURL(url) #get webpage url
content <- unlist(strsplit(content, "\r\n"))
#links <- content[str_detect(string = content, pattern = fixed("http://www.gpo.gov:80/fdsys/pkg/WCPD"))]
links <- content[str_detect(string = content, pattern = fixed("http://www.gpo.gov:80/fdsys/pkg/"))]
#for some reason the regex is being weird so I've had to split this into multiple steps
links2 <- str_replace_all(string = links,
pattern = ".*(http://www\\.gpo\\.gov:80/fdsys/pkg/.*?\").*",
replacement = "\\1")
links2 <- str_replace_all(links2, "\"$", "")
links2 <- links2[!str_detect(links2, "pdf$")]
titles <- content[str_detect(string = content, pattern = "<td colspan=\"2\"><span>.*</td>")]
titles2 <- str_replace_all(string = titles,
pattern = ".*<td colspan=\"2\"><span>(.*)</td>.*",
replacement = "\\1")
cat(paste0(as.character(length(titles2) == length(links2)), "\n"))
if(length(titles2) == length(links2)){
result <- data.frame(year = year, month = month, title = titles2, links = links2, stringsAsFactors = F)
return(result)
} else{
result <- data.frame(year = year, month = month, title = rep("?", length(links2)), links = links2, stringsAsFactors = F)
return(result)
}
})
result <- ldply(result)
return(result)
}
gpoDocNums <- read.csv(file = "data/gpoDocNumRanges.csv", stringsAsFactors = F)
years <- seq(from = 1993, to = 2014, by = 1)
load("data/gpoPresidentialDocuments.RData")
presDocs2 <- ldply(presDocs)
downloadHTML <- function(url){
print(url)
myOpts = curlOptions(verbose = T)
Sys.sleep(0.1)
content <- getURL(url, .opts=myOpts) #get webpage url
return(data.frame(links = url, doc.html = content))
}
html <- lapply(presDocs2$links[1:10], downloadHTML)
html <- ldply(html)
View(html)
downloadHTML <- function(url){
print(url)
myOpts = curlOptions(verbose = F)
Sys.sleep(0.01)
content <- getURL(url, .opts=myOpts) #get webpage url
return(data.frame(links = url, doc.html = content))
}
html <- lapply(presDocs2$links, downloadHTML)
presDocs2[presDocs2$year == "2000", ]$links
html <- lapply(presDocs2[presDocs2$year == "2000", ]$links, downloadHTML)
html <- ldply(html)
presDocs2 <- merge(presDocs2, html)
presDocs2$doc.text <- str_replace_all(presDocs2$doc.html, "<.*?>", "") #remove html tags
ostp <- presDocs2 %>%
filter(str_detect(doc.text, "Office of Science and Technology"))
View(ostp)
sum(presDocs2$doc.text == "")
ostp$doc.text[1]
cat(ostp$doc.text[1])
cat(ostp$doc.text[2])
rm(list = ls())
library(RCurl)
library(stringr)
library(plyr)
library(dplyr)
year <- "2014"
month <- "02"
scrapeGPO <- function(year){
months <- seq(from = 1, to = 12, by = 1)
months <- str_pad(string = months, width = 2, pad = "0")
result <- lapply(months, FUN = function(month){
Sys.sleep(0.01)
url <- paste0("http://www.gpo.gov/fdsys/browse/collection.action?collectionCode=CPD&browsePath=",
year,
"%2F", month,
"&isCollapsed=false&leafLevelBrowse=false")
print(paste0(year, ", ", month))
content <- getURL(url) #get webpage url
content <- unlist(strsplit(content, "\r\n"))
#links <- content[str_detect(string = content, pattern = fixed("http://www.gpo.gov:80/fdsys/pkg/WCPD"))]
links <- content[str_detect(string = content, pattern = fixed("http://www.gpo.gov:80/fdsys/pkg/"))]
#for some reason the regex is being weird so I've had to split this into multiple steps
links2 <- str_replace_all(string = links,
pattern = ".*(http://www\\.gpo\\.gov:80/fdsys/pkg/.*?\").*",
replacement = "\\1")
links2 <- str_replace_all(links2, "\"$", "")
links2 <- links2[!str_detect(links2, "pdf$")]
titles <- content[str_detect(string = content, pattern = "<td colspan=\"2\"><span>.*</td>")]
titles2 <- str_replace_all(string = titles,
pattern = ".*<td colspan=\"2\"><span>(.*)</td>.*",
replacement = "\\1")
cat(paste0(as.character(length(titles2) == length(links2)), "\n"))
if(length(titles2) == length(links2)){
result <- data.frame(year = year, month = month, title = titles2, links = links2, stringsAsFactors = F)
return(result)
} else{
result <- data.frame(year = year, month = month, title = rep("?", length(links2)), links = links2, stringsAsFactors = F)
return(result)
}
})
result <- ldply(result)
return(result)
}
gpoDocNums <- read.csv(file = "data/gpoDocNumRanges.csv", stringsAsFactors = F)
years <- seq(from = 1993, to = 2014, by = 1)
load("data/gpoPresidentialDocuments.RData")
presDocs2 <- ldply(presDocs)
downloadHTML <- function(url){
print(url)
myOpts = curlOptions(verbose = F)
Sys.sleep(0.01)
content <- getURL(url, .opts=myOpts) #get webpage url
return(data.frame(links = url, doc.html = content))
}
html <- lapply(presDocs2$links, downloadHTML)
html <- ldply(html)
presDocs2 <- merge(presDocs2, html)
presDocs2$doc.text <- str_replace_all(presDocs2$doc.html, "<.*?>", "") #remove html tags
save(presDocs, presDocs2, file = "data/gpoPresidentialDocuments.RData")
ostp <- presDocs2 %>%
filter(str_detect(doc.text, "Office of Science and Technology"))
View(ostp)
sum(presDocs2$doc.html == "")
a <- nchar(presDocs2$doc.html)
a <- nchar(presDocs2$doc.text)
hist(a)
summary(a)
presDocs2$doc.text[1]
